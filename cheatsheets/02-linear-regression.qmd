---
title: "Linear Regression â€” przewiduj wartoÅ›ci liczbowe"
format:
  html:
    code-tools: true
---

## ğŸ“ˆ Czym jest Linear Regression?

**Linear Regression** to jeden z najprostszych i najczÄ™Å›ciej uÅ¼ywanych algorytmÃ³w ML do **przewidywania wartoÅ›ci liczbowych** (np. ceny, temperatury, sprzedaÅ¼y). Szuka najlepszej linii prostej, ktÃ³ra opisuje zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennymi.

::: {.callout-note}
## ğŸ’¡ Intuicja matematyczna
Szukamy takiej linii `y = ax + b`, ktÃ³ra najlepiej "przechodzi" przez nasze punkty danych. Algorytm automatycznie dobiera optymalne wartoÅ›ci `a` (slope) i `b` (intercept).
:::

---

## ğŸ  Praktyczny przykÅ‚ad: predykcja cen mieszkaÅ„

```{python}
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Tworzenie przykÅ‚adowych danych mieszkaÅ„
np.random.seed(42)
n_mieszkan = 1000

data = pd.DataFrame({
    'powierzchnia': np.random.normal(70, 25, n_mieszkan),
    'liczba_pokoi': np.random.randint(1, 5, n_mieszkan),
    'wiek_budynku': np.random.randint(0, 50, n_mieszkan),
    'odleglosc_centrum': np.random.exponential(5, n_mieszkan)
})

# Realistyczna formuÅ‚a ceny (z szumem)
data['cena'] = (
    data['powierzchnia'] * 8000 +           # 8k za mÂ²
    data['liczba_pokoi'] * 15000 +          # 15k za pokÃ³j
    (50 - data['wiek_budynku']) * 2000 +    # starsze = taÅ„sze
    data['odleglosc_centrum'] * (-3000) +   # dalej = taÅ„sze
    np.random.normal(0, 50000, n_mieszkan)  # szum losowy
)

print("Podstawowe statystyki:")
print(data.describe())
```

---

## ğŸ”§ Trenowanie modelu krok po kroku

### 1) Przygotowanie danych

```{python}
# Sprawdzenie korelacji - ktÃ³re zmienne sÄ… najwaÅ¼niejsze?
correlation = data.corr()['cena'].sort_values(ascending=False)
print("Korelacja z cenÄ…:")
print(correlation)

# PodziaÅ‚ na features (X) i target (y)
X = data[['powierzchnia', 'liczba_pokoi', 'wiek_budynku', 'odleglosc_centrum']]
y = data['cena']

# PodziaÅ‚ train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Dane treningowe: {X_train.shape[0]} mieszkaÅ„")
print(f"Dane testowe: {X_test.shape[0]} mieszkaÅ„")
```

### 2) Trenowanie modelu

```{python}
# U}tworzenie i trenowanie modelu
model = LinearRegression()
model.fit(X_train, y_train)

# Sprawdzenie wspÃ³Å‚czynnikÃ³w
print("WspÃ³Å‚czynniki modelu:")
for feature, coef in zip(X.columns, model.coef_):
    print(f"{feature}: {coef:.0f} zÅ‚")
print(f"Intercept (staÅ‚a): {model.intercept_:.0f} zÅ‚")
```

### 3) Ewaluacja wynikÃ³w

```{python}
# Predykcje na zbiorze testowym
y_pred = model.predict(X_test)

# Metryki
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nWyniki modelu:")
print(f"Mean Absolute Error: {mae:.0f} zÅ‚")
print(f"RÂ² Score: {r2:.3f}")
print(f"Åšredni bÅ‚Ä…d to {mae/data['cena'].mean()*100:.1f}% ceny mieszkania")

# PrzykÅ‚adowe predykcje
for i in range(5):
    rzeczywista = y_test.iloc[i]
    przewidywana = y_pred[i]
    bÅ‚Ä…d = abs(rzeczywista - przewidywana)
    print(f"Mieszkanie {i+1}: rzeczywista={rzeczywista:.0f}zÅ‚, "
          f"przewidywana={przewidywana:.0f}zÅ‚, bÅ‚Ä…d={bÅ‚Ä…d:.0f}zÅ‚")
```

---

## ğŸ“Š Wizualizacja wynikÃ³w

```{python}
#| label: fig-regression-analysis
#| fig-cap: "Analiza wynikÃ³w modelu Linear Regression"
#| fig-width: 10
#| fig-height: 6
#| warning: false

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# PrzykÅ‚adowe dane mieszkaÅ„ (powtarzamy dla demonstracji)
np.random.seed(42)
n_mieszkan = 1000

data = pd.DataFrame({
    'powierzchnia': np.random.normal(70, 25, n_mieszkan),
    'liczba_pokoi': np.random.randint(1, 5, n_mieszkan),
    'wiek_budynku': np.random.randint(0, 50, n_mieszkan),
    'odleglosc_centrum': np.random.exponential(5, n_mieszkan)
})

data['cena'] = (
    data['powierzchnia'] * 8000 +
    data['liczba_pokoi'] * 15000 +
    (50 - data['wiek_budynku']) * 2000 +
    data['odleglosc_centrum'] * (-3000) +
    np.random.normal(0, 50000, n_mieszkan)
)

# Przygotowanie i trenowanie modelu
X = data[['powierzchnia', 'liczba_pokoi', 'wiek_budynku', 'odleglosc_centrum']]
y = data['cena']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Wykres: rzeczywiste vs przewidywane ceny
plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Rzeczywiste ceny')
plt.ylabel('Przewidywane ceny')
plt.title('Rzeczywiste vs Przewidywane')

plt.subplot(1, 2, 2)
residuals = y_test - y_pred
plt.scatter(y_pred, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Przewidywane ceny')
plt.ylabel('Residuals (bÅ‚Ä™dy)')
plt.title('Analiza residuals')

plt.tight_layout()
plt.show()
```

---

## ğŸ¯ Praktyczne zastosowania Linear Regression

### 1) **Biznesowe**
```{python}
# Przewidywanie sprzedaÅ¼y na podstawie budÅ¼etu marketingowego
sales_data = pd.DataFrame({
    'marketing_budget': [10000, 15000, 20000, 25000, 30000],
    'sales': [100000, 140000, 180000, 220000, 260000]
})

model_sales = LinearRegression()
model_sales.fit(sales_data[['marketing_budget']], sales_data['sales'])

# "JeÅ›li zwiÄ™kszÄ™ budÅ¼et do 35k, sprzedaÅ¼ wzroÅ›nie do:"
new_sales = model_sales.predict([[35000]])
print(f"Przewidywana sprzedaÅ¼ przy budÅ¼ecie 35k: {new_sales[0]:.0f}")
```

### 2) **Analizy finansowe**
```{python}
# Relacja miÄ™dzy PKB a konsumpcjÄ…
economics_data = pd.DataFrame({
    'pkb_per_capita': [25000, 30000, 35000, 40000, 45000],
    'konsumpcja': [18000, 21000, 24000, 27000, 30000]
})

model_econ = LinearRegression()
model_econ.fit(economics_data[['pkb_per_capita']], economics_data['konsumpcja'])

# WspÃ³Å‚czynnik skÅ‚onnoÅ›ci do konsumpcji
print(f"Na kaÅ¼de dodatkowe 1000zÅ‚ PKB, konsumpcja roÅ›nie o: {model_econ.coef_[0]:.0f}zÅ‚")
```

---

## âš ï¸ NajczÄ™stsze puÅ‚apki i jak ich unikaÄ‡

### 1) **Overfitting z wieloma zmiennymi**
```{python}
# ZÅO: za duÅ¼o features wzglÄ™dem danych
# JeÅ›li masz 100 mieszkaÅ„, nie uÅ¼ywaj 50 features!

# DOBRZE: zasada kciuka
def check_features_ratio(X, y):
    ratio = len(y) / X.shape[1]
    if ratio < 10:
        print(f"âš ï¸ Uwaga: masz tylko {ratio:.1f} obserwacji na feature!")
        print("RozwaÅ¼: wiÄ™cej danych lub mniej features")
    else:
        print(f"âœ… OK: {ratio:.1f} obserwacji na feature")

check_features_ratio(X_train, y_train)
```

### 2) **Sprawdzanie zaÅ‚oÅ¼eÅ„ linearnoÅ›ci**
```{python}
# SprawdÅº czy zaleÅ¼noÅ›ci sÄ… rzeczywiÅ›cie liniowe
from scipy import stats

for col in X.columns:
    correlation, p_value = stats.pearsonr(data[col], data['cena'])
    print(f"{col}: korelacja={correlation:.3f}, p-value={p_value:.3f}")
    
    if abs(correlation) < 0.1:
        print(f"âš ï¸ {col} ma sÅ‚abÄ… korelacjÄ™ - moÅ¼e nie byÄ‡ przydatna")
```

### 3) **WielokoliniowoÅ›Ä‡** (features korelujÄ… miÄ™dzy sobÄ…)

```{python}
#| label: fig-correlation-heatmap  
#| fig-cap: "Mapa korelacji miÄ™dzy zmiennymi"
#| fig-width: 8
#| fig-height: 6
#| warning: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# PrzykÅ‚adowe dane features (demonstracja)
np.random.seed(42)
n_samples = 1000

X = pd.DataFrame({
    'powierzchnia': np.random.normal(70, 25, n_samples),
    'liczba_pokoi': np.random.randint(1, 5, n_samples),
    'wiek_budynku': np.random.randint(0, 50, n_samples),
    'odleglosc_centrum': np.random.exponential(5, n_samples)
})

# SprawdÅº korelacje miÄ™dzy features
plt.figure(figsize=(8, 6))
correlation_matrix = X.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Korelacje miÄ™dzy features')
plt.show()

# JeÅ›li korelacja miÄ™dzy features > 0.8, usuÅ„ jednÄ… z nich!
```

---

## ğŸ”§ Parametry do tuningu

```{python}
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline

# 1) Standardization - gdy features majÄ… rÃ³Å¼ne skale
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# 2) Polynomial Features - dla nieliniowych zaleÅ¼noÅ›ci
poly_model = Pipeline([
    ('poly', PolynomialFeatures(degree=2)),
    ('linear', LinearRegression())
])
poly_model.fit(X_train, y_train)

poly_pred = poly_model.predict(X_test)
poly_r2 = r2_score(y_test, poly_pred)
print(f"Polynomial Regression RÂ²: {poly_r2:.3f}")

# 3) Regularization - Ridge i Lasso
from sklearn.linear_model import Ridge, Lasso

ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
ridge_r2 = r2_score(y_test, ridge.predict(X_test))

lasso = Lasso(alpha=1.0)
lasso.fit(X_train, y_train)
lasso_r2 = r2_score(y_test, lasso.predict(X_test))

print(f"Ridge RÂ²: {ridge_r2:.3f}")
print(f"Lasso RÂ²: {lasso_r2:.3f}")
```

---

## ğŸŒ Real-world przykÅ‚ady zastosowaÅ„

1. **E-commerce:** Przewidywanie wartoÅ›ci Å¼yciowej klienta (LTV)
2. **NieruchomoÅ›ci:** Automatyczna wycena domÃ³w (Zillow)
3. **Finanse:** Scoring kredytowy, przewidywanie cen akcji
4. **Marketing:** ROI kampanii reklamowych
5. **Supply Chain:** Prognozowanie popytu na produkty

::: {.callout-tip}
## ğŸ’¡ Kiedy uÅ¼ywaÄ‡ Linear Regression?

**âœ… UÅ»YJ GDY:**
- Przewidujesz wartoÅ›ci liczbowe (continuous target)
- ZaleÅ¼noÅ›ci wydajÄ… siÄ™ liniowe
- Chcesz interpretowalny model
- Masz stosunkowo maÅ‚o features

**âŒ NIE UÅ»YWAJ GDY:**
- Target jest kategoryczny (uÅ¼yj klasyfikacji)
- ZaleÅ¼noÅ›ci sÄ… bardzo nieliniowe (uÅ¼yj Random Forest, XGBoost)
- Masz tysiÄ…ce features (uÅ¼yj regularization)
:::

**NastÄ™pna Å›ciÄ…gawka:** [Decision Trees - klasyfikacja](03-decision-trees.qmd) ğŸŒ³
