{
  "hash": "0a25a308961d0759adeeb4b796f75e43",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Wprowadzenie do Machine Learning â€” fundament\"\nformat:\n  html:\n    code-tools: true\n---\n\n## ğŸ¤– Czym jest Machine Learning?\n\n**Machine Learning (ML)** to dziedzina informatyki, ktÃ³ra pozwala komputerom **uczyÄ‡ siÄ™ i podejmowaÄ‡ decyzje na podstawie danych**, bez koniecznoÅ›ci programowania kaÅ¼dej reguÅ‚y z gÃ³ry.\n\n::: {.callout-note}\n## ğŸ’¡ Intuicja\nZamiast pisaÄ‡ kod \"jeÅ›li temperatura > 25Â°C, to bÄ™dzie sÅ‚onecznie\", **ML pozwala algorytmowi samemu odkryÄ‡** te zaleÅ¼noÅ›ci z historycznych danych pogodowych.\n:::\n\n---\n\n## ğŸ“Š GÅ‚Ã³wne rodzaje ML\n\n### 1) **Supervised Learning** (Uczenie nadzorowane)\n**Mamy dane + znamy prawidÅ‚owe odpowiedzi**\n\n::: {#e1e3ccc0 .cell execution_count=1}\n``` {.python .cell-code}\n# PrzykÅ‚ad: predykcja ceny domu\n# Dane wejÅ›ciowe: powierzchnia, lokalizacja, rok budowy\n# Cel: przewidzieÄ‡ cenÄ™\n\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# PrzykÅ‚adowe dane\ndata = pd.DataFrame({\n    'powierzchnia': [50, 75, 100, 120, 150],\n    'rok_budowy': [1990, 2000, 2010, 2015, 2020],\n    'cena': [300000, 400000, 550000, 650000, 800000]  # znamy prawdziwe ceny!\n})\n\n# Trenowanie modelu\nmodel = LinearRegression()\nX = data[['powierzchnia', 'rok_budowy']]\ny = data['cena']\nmodel.fit(X, y)\n\n# Predykcja dla nowego domu\nnowy_dom = [[90, 2005]]\nprzewidywana_cena = model.predict(nowy_dom)\n\n# Zapisz wyniki do zmiennych dla expandera\ndane_treningowe = data.to_string()\nwynik_predykcji = f\"Przewidywana cena: {przewidywana_cena[0]:.0f} zÅ‚\"\n\nprint(\"Dane treningowe:\")\nprint(dane_treningowe)\nprint(f\"\\nPredykcja dla domu 90mÂ², rok 2005:\")\nprint(wynik_predykcji)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## PokaÅ¼ wyniki predykcji cen\n\n::: {#a908be62 .cell execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\nDane treningowe:\n   powierzchnia  rok_budowy    cena\n0            50        1990  300000\n1            75        2000  400000\n2           100        2010  550000\n3           120        2015  650000\n4           150        2020  800000\n\nPredykcja dla domu 90mÂ², rok 2005:\nPrzewidywana cena: 493819 zÅ‚\n```\n:::\n:::\n\n\n:::\n\n**Real-world zastosowania:**\n\n- Predykcja cen akcji/nieruchomoÅ›ci\n- Diagnoza medyczna (klasyfikacja chorÃ³b)\n- Filtrowanie spamu w emailach\n- Rozpoznawanie mowy/obrazÃ³w\n\n---\n\n### 2) **Unsupervised Learning** (Uczenie nienadzorowane)  \n**Mamy tylko dane, szukamy ukrytych wzorcÃ³w**\n\n::: {#a33ba751 .cell execution_count=3}\n``` {.python .cell-code}\n# PrzykÅ‚ad: segmentacja klientÃ³w sklepu\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# Dane klientÃ³w: wiek i wydatki miesiÄ™czne\nklienci = pd.DataFrame({\n    'wiek': [25, 30, 35, 22, 28, 45, 50, 55, 60, 65],\n    'wydatki': [2000, 2500, 3000, 1800, 2200, 4000, 4500, 3500, 3000, 2800]\n})\n\n# Grupowanie klientÃ³w w 3 segmenty\nkmeans = KMeans(n_clusters=3, random_state=42)\nklienci['segment'] = kmeans.fit_predict(klienci[['wiek', 'wydatki']])\n\n# Przygotuj wyniki do wyÅ›wietlenia\ndane_klientow = klienci.head().to_string()\nsegmenty_info = []\nfor i in range(3):\n    segment = klienci[klienci['segment'] == i]\n    segmenty_info.append(f\"Segment {i}: Å›redni wiek {segment['wiek'].mean():.0f}, Å›rednie wydatki {segment['wydatki'].mean():.0f}\")\n\nprzyklad_predykcji = kmeans.predict([[30, 2500]])[0]\n\nprint(\"Dane klientÃ³w:\")\nprint(dane_klientow)\nprint(\"\\nSegmenty klientÃ³w:\")\nfor info in segmenty_info:\n    print(info)\nprint(f\"\\nPrzykÅ‚ad: klient 30 lat, wydaje 2500zÅ‚ -> segment {przyklad_predykcji}\")\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## PokaÅ¼ wyniki segmentacji klientÃ³w\n\n::: {#f1227a72 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\nDane klientÃ³w:\n   wiek  wydatki  segment\n0    25     2000        0\n1    30     2500        2\n2    35     3000        2\n3    22     1800        0\n4    28     2200        0\n\nSegmenty klientÃ³w:\nSegment 0: Å›redni wiek 25, Å›rednie wydatki 2000\nSegment 1: Å›redni wiek 50, Å›rednie wydatki 4000\nSegment 2: Å›redni wiek 48, Å›rednie wydatki 2825\n\nPrzykÅ‚ad: klient 30 lat, wydaje 2500zÅ‚ -> segment 2\n```\n:::\n:::\n\n\n:::\n\n\n**Real-world zastosowania:**\n\n- Segmentacja klientÃ³w (marketing)\n- Wykrywanie anomalii (cyberbezpieczeÅ„stwo)\n- Analiza koszykowa (co kupujÄ… razem)\n- Kompresja danych\n\n---\n\n### 3) **Reinforcement Learning** (Uczenie ze wzmocnieniem)\n**Agent uczy siÄ™ przez interakcjÄ™ i nagrody/kary**\n\n::: {#aab331f5 .cell execution_count=5}\n``` {.python .cell-code}\n# PrzykÅ‚ad koncepcyjny: optymalizacja reklam\nclass SimpleAgent:\n    def __init__(self):\n        # Jakie reklamy pokazywaÄ‡: [\"sportowe\", \"technologiczne\", \"modowe\"]\n        self.ad_types = [\"sportowe\", \"technologiczne\", \"modowe\"]\n        self.rewards = [0, 0, 0]  # nagrody za kaÅ¼dy typ\n        self.counts = [0, 0, 0]   # ile razy pokazane\n    \n    def choose_ad(self):\n        # Wybierz reklamÄ™ z najwyÅ¼szÄ… Å›redniÄ… nagrodÄ…\n        avg_rewards = [r/max(c,1) for r, c in zip(self.rewards, self.counts)]\n        return avg_rewards.index(max(avg_rewards))\n    \n    def update_reward(self, ad_type, clicked):\n        # Aktualizuj nagrody na podstawie klikniÄ™Ä‡\n        self.counts[ad_type] += 1\n        if clicked:\n            self.rewards[ad_type] += 1\n    \n    def get_stats(self):\n        stats_list = []\n        for i, ad_type in enumerate(self.ad_types):\n            rate = self.rewards[i] / max(self.counts[i], 1) * 100\n            stats_list.append(f\"{ad_type}: {self.counts[i]} pokazaÅ„, {self.rewards[i]} klikniÄ™Ä‡ ({rate:.1f}%)\")\n        return stats_list\n\n# Symulacja\nimport numpy as np\nnp.random.seed(42)\n\nagent = SimpleAgent()\nsymulacja_wyniki = []\nsymulacja_wyniki.append(\"ğŸ¯ Symulacja optymalizacji reklam:\")\nsymulacja_wyniki.append(\"Agent uczy siÄ™, ktÃ³re reklamy dziaÅ‚ajÄ… najlepiej...\")\n\nfor day in range(10):\n    ad = agent.choose_ad()\n    # RÃ³Å¼ne prawdopodobieÅ„stwa klikniÄ™Ä‡ dla rÃ³Å¼nych typÃ³w reklam\n    click_probs = [0.1, 0.3, 0.2]  # technologiczne najlepsze\n    clicked = np.random.random() < click_probs[ad]\n    agent.update_reward(ad, clicked)\n    symulacja_wyniki.append(f\"DzieÅ„ {day+1}: pokazano {agent.ad_types[ad]}, klikniÄ™ta: {clicked}\")\n\nkoncowe_statystyki = agent.get_stats()\n\nfor wynik in symulacja_wyniki:\n    print(wynik)\nprint(\"\\nğŸ“Š KoÅ„cowe statystyki:\")\nfor stat in koncowe_statystyki:\n    print(stat)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## PokaÅ¼ symulacjÄ™ agenta reklamowego\n\n::: {#c35351c4 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\nğŸ¯ Symulacja optymalizacji reklam:\nAgent uczy siÄ™, ktÃ³re reklamy dziaÅ‚ajÄ… najlepiej...\nDzieÅ„ 1: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 2: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 3: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 4: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 5: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 6: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 7: pokazano sportowe, klikniÄ™ta: True\nDzieÅ„ 8: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 9: pokazano sportowe, klikniÄ™ta: False\nDzieÅ„ 10: pokazano sportowe, klikniÄ™ta: False\n\nğŸ“Š KoÅ„cowe statystyki:\nsportowe: 10 pokazaÅ„, 1 klikniÄ™Ä‡ (10.0%)\ntechnologiczne: 0 pokazaÅ„, 0 klikniÄ™Ä‡ (0.0%)\nmodowe: 0 pokazaÅ„, 0 klikniÄ™Ä‡ (0.0%)\n```\n:::\n:::\n\n\n:::\n\n**Real-world zastosowania:**\n\n- Gry komputerowe (AI graczy)\n- Autonomiczne pojazdy\n- Optymalizacja reklam online\n- Roboty przemysÅ‚owe\n\n---\n\n## ğŸ¯ Jak wybraÄ‡ odpowiedni typ ML?\n\n| **Sytuacja** | **Typ ML** | **PrzykÅ‚ad** |\n|-------------|------------|--------------|\n| Masz dane z prawidÅ‚owymi odpowiedziami | **Supervised** | Spam/nie-spam w emailach |\n| Chcesz znaleÅºÄ‡ ukryte grupÑ‹ | **Unsupervised** | Segmentacja klientÃ³w |\n| System ma siÄ™ uczyÄ‡ przez trial & error | **Reinforcement** | Bot do gier |\n\n---\n\n## ğŸ”§ Podstawowe kroki projektu ML\n\n::: {#bbffde18 .cell execution_count=7}\n``` {.python .cell-code}\n# Kompletny workflow ML na przykÅ‚adzie klasyfikacji iris\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# 1. ZaÅ‚aduj i poznaj dane\niris = load_iris()\ndata = pd.DataFrame(iris.data, columns=iris.feature_names)\ndata['target'] = iris.target\ntarget_names = iris.target_names\n\n# 2. Przygotuj dane (czyszczenie, encoding)\nX = data.drop('target', axis=1)\ny = data['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 3. Podziel na train/test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# 4. Wybierz i wytrenuj model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# 5. OceÅ„ wyniki\npredictions = model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\n\n# PrzykÅ‚ad predykcji\nsample_flower = X_test[0:1]\npredicted_class = model.predict(sample_flower)[0]\npredicted_name = target_names[predicted_class]\nactual_name = target_names[y_test.iloc[0]]\n\n# Przygotuj wyniki do wyÅ›wietlenia\nwyniki_workflow = []\nwyniki_workflow.append(\"ğŸ”¬ Kompletny workflow projektu ML\")\nwyniki_workflow.append(\"=\" * 40)\nwyniki_workflow.append(\"1ï¸âƒ£ Dane zaÅ‚adowane:\")\nwyniki_workflow.append(f\"KsztaÅ‚t: {data.shape}\")\nwyniki_workflow.append(f\"Klasy: {target_names}\")\nwyniki_workflow.append(f\"Pierwsze 3 wiersze:\\n{data.head(3).to_string()}\")\nwyniki_workflow.append(f\"\\n2ï¸âƒ£ Dane przeskalowane (pierwsze 3 cechy pierwszej prÃ³bki):\")\nwyniki_workflow.append(f\"Przed: {X.iloc[0, :3].values}\")\nwyniki_workflow.append(f\"Po: {X_scaled[0, :3]}\")\nwyniki_workflow.append(f\"\\n3ï¸âƒ£ PodziaÅ‚ danych:\")\nwyniki_workflow.append(f\"Train: {len(X_train)} prÃ³bek\")\nwyniki_workflow.append(f\"Test: {len(X_test)} prÃ³bek\")\nwyniki_workflow.append(f\"\\n4ï¸âƒ£ Model wytrenowany: RandomForestClassifier\")\nwyniki_workflow.append(f\"\\n5ï¸âƒ£ Wyniki:\")\nwyniki_workflow.append(f\"DokÅ‚adnoÅ›Ä‡: {accuracy:.2%}\")\nwyniki_workflow.append(f\"\\nPrzykÅ‚ad predykcji:\")\nwyniki_workflow.append(f\"Przewidywana klasa: {predicted_name}\")\nwyniki_workflow.append(f\"Rzeczywista klasa: {actual_name}\")\nwyniki_workflow.append(\"âœ… Poprawnie!\" if predicted_name == actual_name else \"âŒ BÅ‚Ä…d\")\n\nfor wynik in wyniki_workflow:\n    print(wynik)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## PokaÅ¼ kompletny workflow ML\n\n::: {#c1087ec1 .cell execution_count=8}\n\n::: {.cell-output .cell-output-stdout}\n```\nğŸ”¬ Kompletny workflow projektu ML\n========================================\n1ï¸âƒ£ Dane zaÅ‚adowane:\nKsztaÅ‚t: (150, 5)\nKlasy: ['setosa' 'versicolor' 'virginica']\nPierwsze 3 wiersze:\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2       0\n1                4.9               3.0                1.4               0.2       0\n2                4.7               3.2                1.3               0.2       0\n\n2ï¸âƒ£ Dane przeskalowane (pierwsze 3 cechy pierwszej prÃ³bki):\nPrzed: [5.1 3.5 1.4]\nPo: [-0.90068117  1.01900435 -1.34022653]\n\n3ï¸âƒ£ PodziaÅ‚ danych:\nTrain: 120 prÃ³bek\nTest: 30 prÃ³bek\n\n4ï¸âƒ£ Model wytrenowany: RandomForestClassifier\n\n5ï¸âƒ£ Wyniki:\nDokÅ‚adnoÅ›Ä‡: 100.00%\n\nPrzykÅ‚ad predykcji:\nPrzewidywana klasa: versicolor\nRzeczywista klasa: versicolor\nâœ… Poprawnie!\n```\n:::\n:::\n\n\n:::\n\n\n---\n\n## ğŸ’¡ NajwaÅ¼niejsze biblioteki Python dla ML\n\n```python\n# Podstawowe przetwarzanie danych\nimport pandas as pd      # DataFrames, CSV, analiza\nimport numpy as np       # obliczenia numeryczne\n\n# Machine Learning\nfrom sklearn import *    # algorytmy ML, preprocessing, metryki\nimport xgboost as xgb   # zaawansowane drzewa decyzyjne\n\n# Wizualizacja\nimport matplotlib.pyplot as plt  # wykresy\nimport seaborn as sns           # piÄ™kne wykresy statystyczne\n\n# Deep Learning\nimport tensorflow as tf  # sieci neuronowe (Google)\nimport torch            # sieci neuronowe (Facebook)\n```\n\n---\n\n::: {.callout-tip}\n## ğŸ¯ Pro tips dla poczÄ…tkujÄ…cych\n\n1. **Zacznij od prostych algorytmÃ³w** - Linear Regression, Decision Trees\n2. **80% czasu to przygotowanie danych** - czyszczenie, eksploracja, feature engineering\n3. **Zawsze sprawdÅº czy model nie jest overfitted** - uÅ¼yj validation set\n4. **Rozumiej swoje dane** przed wyborem algorytmu\n5. **Praktyka > teoria** - rÃ³b duÅ¼o projektÃ³w na rÃ³Å¼nych danych!\n:::\n\n**NastÄ™pna Å›ciÄ…gawka:** [Linear Regression w praktyce](02-linear-regression.qmd) ğŸš€\n\n",
    "supporting": [
      "01-intro-ml_files"
    ],
    "filters": [],
    "includes": {}
  }
}