{
  "hash": "0a25a308961d0759adeeb4b796f75e43",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Wprowadzenie do Machine Learning — fundament\"\nformat:\n  html:\n    code-tools: true\n---\n\n## 🤖 Czym jest Machine Learning?\n\n**Machine Learning (ML)** to dziedzina informatyki, która pozwala komputerom **uczyć się i podejmować decyzje na podstawie danych**, bez konieczności programowania każdej reguły z góry.\n\n::: {.callout-note}\n## 💡 Intuicja\nZamiast pisać kod \"jeśli temperatura > 25°C, to będzie słonecznie\", **ML pozwala algorytmowi samemu odkryć** te zależności z historycznych danych pogodowych.\n:::\n\n---\n\n## 📊 Główne rodzaje ML\n\n### 1) **Supervised Learning** (Uczenie nadzorowane)\n**Mamy dane + znamy prawidłowe odpowiedzi**\n\n::: {#e1e3ccc0 .cell execution_count=1}\n``` {.python .cell-code}\n# Przykład: predykcja ceny domu\n# Dane wejściowe: powierzchnia, lokalizacja, rok budowy\n# Cel: przewidzieć cenę\n\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Przykładowe dane\ndata = pd.DataFrame({\n    'powierzchnia': [50, 75, 100, 120, 150],\n    'rok_budowy': [1990, 2000, 2010, 2015, 2020],\n    'cena': [300000, 400000, 550000, 650000, 800000]  # znamy prawdziwe ceny!\n})\n\n# Trenowanie modelu\nmodel = LinearRegression()\nX = data[['powierzchnia', 'rok_budowy']]\ny = data['cena']\nmodel.fit(X, y)\n\n# Predykcja dla nowego domu\nnowy_dom = [[90, 2005]]\nprzewidywana_cena = model.predict(nowy_dom)\n\n# Zapisz wyniki do zmiennych dla expandera\ndane_treningowe = data.to_string()\nwynik_predykcji = f\"Przewidywana cena: {przewidywana_cena[0]:.0f} zł\"\n\nprint(\"Dane treningowe:\")\nprint(dane_treningowe)\nprint(f\"\\nPredykcja dla domu 90m², rok 2005:\")\nprint(wynik_predykcji)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Pokaż wyniki predykcji cen\n\n::: {#a908be62 .cell execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\nDane treningowe:\n   powierzchnia  rok_budowy    cena\n0            50        1990  300000\n1            75        2000  400000\n2           100        2010  550000\n3           120        2015  650000\n4           150        2020  800000\n\nPredykcja dla domu 90m², rok 2005:\nPrzewidywana cena: 493819 zł\n```\n:::\n:::\n\n\n:::\n\n**Real-world zastosowania:**\n\n- Predykcja cen akcji/nieruchomości\n- Diagnoza medyczna (klasyfikacja chorób)\n- Filtrowanie spamu w emailach\n- Rozpoznawanie mowy/obrazów\n\n---\n\n### 2) **Unsupervised Learning** (Uczenie nienadzorowane)  \n**Mamy tylko dane, szukamy ukrytych wzorców**\n\n::: {#a33ba751 .cell execution_count=3}\n``` {.python .cell-code}\n# Przykład: segmentacja klientów sklepu\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# Dane klientów: wiek i wydatki miesięczne\nklienci = pd.DataFrame({\n    'wiek': [25, 30, 35, 22, 28, 45, 50, 55, 60, 65],\n    'wydatki': [2000, 2500, 3000, 1800, 2200, 4000, 4500, 3500, 3000, 2800]\n})\n\n# Grupowanie klientów w 3 segmenty\nkmeans = KMeans(n_clusters=3, random_state=42)\nklienci['segment'] = kmeans.fit_predict(klienci[['wiek', 'wydatki']])\n\n# Przygotuj wyniki do wyświetlenia\ndane_klientow = klienci.head().to_string()\nsegmenty_info = []\nfor i in range(3):\n    segment = klienci[klienci['segment'] == i]\n    segmenty_info.append(f\"Segment {i}: średni wiek {segment['wiek'].mean():.0f}, średnie wydatki {segment['wydatki'].mean():.0f}\")\n\nprzyklad_predykcji = kmeans.predict([[30, 2500]])[0]\n\nprint(\"Dane klientów:\")\nprint(dane_klientow)\nprint(\"\\nSegmenty klientów:\")\nfor info in segmenty_info:\n    print(info)\nprint(f\"\\nPrzykład: klient 30 lat, wydaje 2500zł -> segment {przyklad_predykcji}\")\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Pokaż wyniki segmentacji klientów\n\n::: {#f1227a72 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\nDane klientów:\n   wiek  wydatki  segment\n0    25     2000        0\n1    30     2500        2\n2    35     3000        2\n3    22     1800        0\n4    28     2200        0\n\nSegmenty klientów:\nSegment 0: średni wiek 25, średnie wydatki 2000\nSegment 1: średni wiek 50, średnie wydatki 4000\nSegment 2: średni wiek 48, średnie wydatki 2825\n\nPrzykład: klient 30 lat, wydaje 2500zł -> segment 2\n```\n:::\n:::\n\n\n:::\n\n\n**Real-world zastosowania:**\n\n- Segmentacja klientów (marketing)\n- Wykrywanie anomalii (cyberbezpieczeństwo)\n- Analiza koszykowa (co kupują razem)\n- Kompresja danych\n\n---\n\n### 3) **Reinforcement Learning** (Uczenie ze wzmocnieniem)\n**Agent uczy się przez interakcję i nagrody/kary**\n\n::: {#aab331f5 .cell execution_count=5}\n``` {.python .cell-code}\n# Przykład koncepcyjny: optymalizacja reklam\nclass SimpleAgent:\n    def __init__(self):\n        # Jakie reklamy pokazywać: [\"sportowe\", \"technologiczne\", \"modowe\"]\n        self.ad_types = [\"sportowe\", \"technologiczne\", \"modowe\"]\n        self.rewards = [0, 0, 0]  # nagrody za każdy typ\n        self.counts = [0, 0, 0]   # ile razy pokazane\n    \n    def choose_ad(self):\n        # Wybierz reklamę z najwyższą średnią nagrodą\n        avg_rewards = [r/max(c,1) for r, c in zip(self.rewards, self.counts)]\n        return avg_rewards.index(max(avg_rewards))\n    \n    def update_reward(self, ad_type, clicked):\n        # Aktualizuj nagrody na podstawie kliknięć\n        self.counts[ad_type] += 1\n        if clicked:\n            self.rewards[ad_type] += 1\n    \n    def get_stats(self):\n        stats_list = []\n        for i, ad_type in enumerate(self.ad_types):\n            rate = self.rewards[i] / max(self.counts[i], 1) * 100\n            stats_list.append(f\"{ad_type}: {self.counts[i]} pokazań, {self.rewards[i]} kliknięć ({rate:.1f}%)\")\n        return stats_list\n\n# Symulacja\nimport numpy as np\nnp.random.seed(42)\n\nagent = SimpleAgent()\nsymulacja_wyniki = []\nsymulacja_wyniki.append(\"🎯 Symulacja optymalizacji reklam:\")\nsymulacja_wyniki.append(\"Agent uczy się, które reklamy działają najlepiej...\")\n\nfor day in range(10):\n    ad = agent.choose_ad()\n    # Różne prawdopodobieństwa kliknięć dla różnych typów reklam\n    click_probs = [0.1, 0.3, 0.2]  # technologiczne najlepsze\n    clicked = np.random.random() < click_probs[ad]\n    agent.update_reward(ad, clicked)\n    symulacja_wyniki.append(f\"Dzień {day+1}: pokazano {agent.ad_types[ad]}, kliknięta: {clicked}\")\n\nkoncowe_statystyki = agent.get_stats()\n\nfor wynik in symulacja_wyniki:\n    print(wynik)\nprint(\"\\n📊 Końcowe statystyki:\")\nfor stat in koncowe_statystyki:\n    print(stat)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Pokaż symulację agenta reklamowego\n\n::: {#c35351c4 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\n🎯 Symulacja optymalizacji reklam:\nAgent uczy się, które reklamy działają najlepiej...\nDzień 1: pokazano sportowe, kliknięta: False\nDzień 2: pokazano sportowe, kliknięta: False\nDzień 3: pokazano sportowe, kliknięta: False\nDzień 4: pokazano sportowe, kliknięta: False\nDzień 5: pokazano sportowe, kliknięta: False\nDzień 6: pokazano sportowe, kliknięta: False\nDzień 7: pokazano sportowe, kliknięta: True\nDzień 8: pokazano sportowe, kliknięta: False\nDzień 9: pokazano sportowe, kliknięta: False\nDzień 10: pokazano sportowe, kliknięta: False\n\n📊 Końcowe statystyki:\nsportowe: 10 pokazań, 1 kliknięć (10.0%)\ntechnologiczne: 0 pokazań, 0 kliknięć (0.0%)\nmodowe: 0 pokazań, 0 kliknięć (0.0%)\n```\n:::\n:::\n\n\n:::\n\n**Real-world zastosowania:**\n\n- Gry komputerowe (AI graczy)\n- Autonomiczne pojazdy\n- Optymalizacja reklam online\n- Roboty przemysłowe\n\n---\n\n## 🎯 Jak wybrać odpowiedni typ ML?\n\n| **Sytuacja** | **Typ ML** | **Przykład** |\n|-------------|------------|--------------|\n| Masz dane z prawidłowymi odpowiedziami | **Supervised** | Spam/nie-spam w emailach |\n| Chcesz znaleźć ukryte grupы | **Unsupervised** | Segmentacja klientów |\n| System ma się uczyć przez trial & error | **Reinforcement** | Bot do gier |\n\n---\n\n## 🔧 Podstawowe kroki projektu ML\n\n::: {#bbffde18 .cell execution_count=7}\n``` {.python .cell-code}\n# Kompletny workflow ML na przykładzie klasyfikacji iris\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# 1. Załaduj i poznaj dane\niris = load_iris()\ndata = pd.DataFrame(iris.data, columns=iris.feature_names)\ndata['target'] = iris.target\ntarget_names = iris.target_names\n\n# 2. Przygotuj dane (czyszczenie, encoding)\nX = data.drop('target', axis=1)\ny = data['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 3. Podziel na train/test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# 4. Wybierz i wytrenuj model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# 5. Oceń wyniki\npredictions = model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\n\n# Przykład predykcji\nsample_flower = X_test[0:1]\npredicted_class = model.predict(sample_flower)[0]\npredicted_name = target_names[predicted_class]\nactual_name = target_names[y_test.iloc[0]]\n\n# Przygotuj wyniki do wyświetlenia\nwyniki_workflow = []\nwyniki_workflow.append(\"🔬 Kompletny workflow projektu ML\")\nwyniki_workflow.append(\"=\" * 40)\nwyniki_workflow.append(\"1️⃣ Dane załadowane:\")\nwyniki_workflow.append(f\"Kształt: {data.shape}\")\nwyniki_workflow.append(f\"Klasy: {target_names}\")\nwyniki_workflow.append(f\"Pierwsze 3 wiersze:\\n{data.head(3).to_string()}\")\nwyniki_workflow.append(f\"\\n2️⃣ Dane przeskalowane (pierwsze 3 cechy pierwszej próbki):\")\nwyniki_workflow.append(f\"Przed: {X.iloc[0, :3].values}\")\nwyniki_workflow.append(f\"Po: {X_scaled[0, :3]}\")\nwyniki_workflow.append(f\"\\n3️⃣ Podział danych:\")\nwyniki_workflow.append(f\"Train: {len(X_train)} próbek\")\nwyniki_workflow.append(f\"Test: {len(X_test)} próbek\")\nwyniki_workflow.append(f\"\\n4️⃣ Model wytrenowany: RandomForestClassifier\")\nwyniki_workflow.append(f\"\\n5️⃣ Wyniki:\")\nwyniki_workflow.append(f\"Dokładność: {accuracy:.2%}\")\nwyniki_workflow.append(f\"\\nPrzykład predykcji:\")\nwyniki_workflow.append(f\"Przewidywana klasa: {predicted_name}\")\nwyniki_workflow.append(f\"Rzeczywista klasa: {actual_name}\")\nwyniki_workflow.append(\"✅ Poprawnie!\" if predicted_name == actual_name else \"❌ Błąd\")\n\nfor wynik in wyniki_workflow:\n    print(wynik)\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Pokaż kompletny workflow ML\n\n::: {#c1087ec1 .cell execution_count=8}\n\n::: {.cell-output .cell-output-stdout}\n```\n🔬 Kompletny workflow projektu ML\n========================================\n1️⃣ Dane załadowane:\nKształt: (150, 5)\nKlasy: ['setosa' 'versicolor' 'virginica']\nPierwsze 3 wiersze:\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                5.1               3.5                1.4               0.2       0\n1                4.9               3.0                1.4               0.2       0\n2                4.7               3.2                1.3               0.2       0\n\n2️⃣ Dane przeskalowane (pierwsze 3 cechy pierwszej próbki):\nPrzed: [5.1 3.5 1.4]\nPo: [-0.90068117  1.01900435 -1.34022653]\n\n3️⃣ Podział danych:\nTrain: 120 próbek\nTest: 30 próbek\n\n4️⃣ Model wytrenowany: RandomForestClassifier\n\n5️⃣ Wyniki:\nDokładność: 100.00%\n\nPrzykład predykcji:\nPrzewidywana klasa: versicolor\nRzeczywista klasa: versicolor\n✅ Poprawnie!\n```\n:::\n:::\n\n\n:::\n\n\n---\n\n## 💡 Najważniejsze biblioteki Python dla ML\n\n```python\n# Podstawowe przetwarzanie danych\nimport pandas as pd      # DataFrames, CSV, analiza\nimport numpy as np       # obliczenia numeryczne\n\n# Machine Learning\nfrom sklearn import *    # algorytmy ML, preprocessing, metryki\nimport xgboost as xgb   # zaawansowane drzewa decyzyjne\n\n# Wizualizacja\nimport matplotlib.pyplot as plt  # wykresy\nimport seaborn as sns           # piękne wykresy statystyczne\n\n# Deep Learning\nimport tensorflow as tf  # sieci neuronowe (Google)\nimport torch            # sieci neuronowe (Facebook)\n```\n\n---\n\n::: {.callout-tip}\n## 🎯 Pro tips dla początkujących\n\n1. **Zacznij od prostych algorytmów** - Linear Regression, Decision Trees\n2. **80% czasu to przygotowanie danych** - czyszczenie, eksploracja, feature engineering\n3. **Zawsze sprawdź czy model nie jest overfitted** - użyj validation set\n4. **Rozumiej swoje dane** przed wyborem algorytmu\n5. **Praktyka > teoria** - rób dużo projektów na różnych danych!\n:::\n\n**Następna ściągawka:** [Linear Regression w praktyce](02-linear-regression.qmd) 🚀\n\n",
    "supporting": [
      "01-intro-ml_files"
    ],
    "filters": [],
    "includes": {}
  }
}